from io import BytesIO
from dotenv import load_dotenv

import os
import re
import requests
import pandas as pd
import streamlit as st
from streamlit import session_state as ss
from ranker import get_rating, CANDIDATE_RANKING_PROMPT, INTERVIEWER_RANKING_PROMPT

import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound, APIError


load_dotenv()

# Google Spreadsheets API Service account key
SERVICE_ACCOUNT_INFO = {
    "type": os.getenv('gs_type'),
    "project_id": os.getenv('gs_project_id'),
    "private_key_id": os.getenv('gs_private_key_id'),
    "private_key": os.getenv('gs_private_key'),
    "client_email": os.getenv('gs_client_email'),
    "client_id": os.getenv('gs_client_id'),
    "auth_uri": os.getenv('gs_auth_uri'),
    "token_uri": os.getenv('gs_token_uri'),
    "auth_provider_x509_cert_url": os.getenv('gs_auth_provider_x509_cert_url'),
    "client_x509_cert_url": os.getenv('gs_client_x509_cert_url'),
    "universe_domain": os.getenv('gs_universe_domain')
}

# Permitted zones
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# Google Spreadsheets authorization 
creds = Credentials.from_service_account_info(SERVICE_ACCOUNT_INFO, scopes=SCOPES)
client = gspread.authorize(creds)

    
# ---------------------------
# UI
# ---------------------------
ss.setdefault('completion_bytes', b'')
st.set_page_config(page_title="–†–∞–Ω–∂–∏—Ä–æ–≤—â–∏–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", layout="wide")

st.markdown(
    """
        <style>
            .stButton > button {
                float: right;
            }
        </style>
    """,
    unsafe_allow_html=True
)

st.title("üîé –ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤")

# –û–±—â–µ–µ –ø–æ–ª–µ –≤–≤–æ–¥–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
requirements = st.text_area(
    "‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏:", 
    height=400, 
    key=f"requirements"
)

# –í–∫–ª–∞–¥–∫–∏
tab_candidates, tab_interviewers = st.tabs(["–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–∞", "–ü–æ–¥–±–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞"])



# –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ –ø–æ–¥–±–æ—Ä–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
with tab_candidates:
    title = "–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"
    key_prefix="candidate"

    subheader_column, rank_button_column = st.columns([1, 1])
    subheader_column.subheader(title)

    # –û—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
    departments_map = {
        '1C': '–ö–∞—Ä—Ç–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π 1—Å',
        'Data Platform': '–ö–∞—Ä—Ç–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π DP'
    }

    selected_department = st.selectbox(
        "üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç:",
        list(departments_map.keys()),
        key=f"department_direction"
    )

    selected_sheet_name = None
    show_candidates = False
    include_staffing = False
    include_laboratory = False

    if requirements and selected_department:
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã
            
            candidates_spreadsheet = client.open(departments_map[selected_department])
            worksheets = candidates_spreadsheet.worksheets()
            sheet_names = [ws.title for ws in worksheets]                
            selected_sheet_name = st.selectbox(
                "üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é:",
                sheet_names,
                key=f"{key_prefix}_direction"
            )

            show_candidates = st.checkbox(
                "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
                value=True,
                key=f"chk_{key_prefix}s"
            )

            with st.container():
                st.markdown("###### –í–∫–ª—é—á–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
                include_staffing = st.checkbox("–°—Ç–∞—Ñ—Ñ–∏–Ω–≥", key=f"chk_{key_prefix}s_staffing")
                include_laboratory = st.checkbox("–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é", key=f"chk_{key_prefix}s_laboratory")

        except SpreadsheetNotFound:
            st.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞!", icon="üö®")
        except APIError as e:
            st.error(f"–û—à–∏–±–∫–∞ API: {e}", icon="üö®")
    else:
        st.info("–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é", icon="üí°")
    
    # –ö–æ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    if requirements and selected_sheet_name:
        candidates_spreadsheet = client.open(departments_map[selected_department])
        candidates_worksheet = candidates_spreadsheet.worksheet(selected_sheet_name)
        candidates_values = candidates_worksheet.get_all_values()
        competentions_df = pd.DataFrame(candidates_values[6:], columns=candidates_values[5])
        competentions_df.columns = ['–ù–∞–≤—ã–∫'] + list(competentions_df.columns[1:])
        unsupported_columns = [column for column in competentions_df.columns if 'Unnamed' in column]
        competentions_df.drop(columns=unsupported_columns, inplace=True)

        empty_competentions_ids = competentions_df[competentions_df['–ù–∞–≤—ã–∫'].str.strip().str.len() == 0].index
        competentions_df.drop(index=empty_competentions_ids, inplace=True)
        competentions_df.dropna(subset='–ù–∞–≤—ã–∫', inplace=True)

        # –£–¥–∞–ª—è—é –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–≤ (–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—ã –Ω–µ –≤—ã—Å—Ç—É–ø–∞—é—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤)
        pattern = r"(cnslt)"    
        cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
        competentions_df.drop(columns=cols_to_drop, inplace=True)

        if not include_staffing:
            pattern = r"(staff)"
            
            cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
            competentions_df.drop(columns=cols_to_drop, inplace=True)

        if not include_laboratory:
            pattern = r"(laba)"
            
            cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
            competentions_df.drop(columns=cols_to_drop, inplace=True)

        if show_candidates:
            st.subheader("–°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
            st.dataframe(competentions_df, height=250)

        if rank_button_column.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ", key=f"btn_{key_prefix}s_rank"):
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Ä–∞–Ω–∂–∏—Ä
            rating = get_rating(
                requirements=requirements,
                competentions=competentions_df.to_markdown(index=False),
                ranking_prompt=CANDIDATE_RANKING_PROMPT
            )

            # –í—ã–≤–æ–∂—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_data = []
            for worker in rating:
                result_data.append({
                    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': worker.name,
                    '–†–µ–π—Ç–∏–Ω–≥': f'{worker.rating}%',
                    '–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏': ', '.join(worker.goods),
                    '–ß—Ç–æ –ø–æ–¥—Ç—è–Ω—É—Ç—å': ', '.join(worker.bads)
                })

            st.success("–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
            st.dataframe(pd.DataFrame(result_data), width=1600)


# –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ –ø–æ–¥–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
with tab_interviewers:
    title = "–ü–æ–∏—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞"
    key_prefix="interviewer"

    subheader_column, rank_button_column = st.columns([1, 1])
    subheader_column.subheader(title)

    # –û—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
    interviewers_spreadsheet = client.open("–ö–∞—Ä—Ç–∞ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤")

    interviewers_selected_sheet_name = None
    show_interviewers = False
    include_consultant = False

    if requirements:
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã
            worksheets = interviewers_spreadsheet.worksheets()
            sheet_names = [ws.title for ws in worksheets]                
            interviewers_selected_sheet_name = st.selectbox(
                "üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é:",
                sheet_names,
                key = f"{key_prefix}_direction"
            )

            show_interviewers = st.checkbox(
                "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤",
                value=True,
                key = f"chk_{key_prefix}s"
            )

        except SpreadsheetNotFound:
            st.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞!", icon="üö®")
        except APIError as e:
            st.error(f"–û—à–∏–±–∫–∞ API: {e}", icon="üö®")
    else:
        st.info("–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é", icon="üí°")
    
    # –ö–æ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    if requirements and interviewers_selected_sheet_name and selected_department != '1C':
        #–ü–æ–¥–≥—Ä—É–∂–∞–µ–º –∫–∞—Ä—Ç—É –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
        interviewers_worksheet = interviewers_spreadsheet.worksheet(interviewers_selected_sheet_name)
        interviewers_values = interviewers_worksheet.get_all_values()
        interviewers_df = pd.DataFrame(interviewers_values[1:], columns=interviewers_values[0])
        interviewers_df.dropna(subset='–°–æ—Ç—Ä—É–¥–Ω–∏–∫', inplace=True)

        #–ü–æ–¥–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
        #Todo: –°–¥–µ–ª–∞—Ç—å –ø–æ–¥–≥—Ä—É–∑–∫—É 1 —Ä–∞–∑ –∑–∞ –≤–µ—Å—å —Å–µ–∞–Ω—Å
        interviewers_candidates_spreadsheet = client.open(departments_map[selected_department])
        interviewers_candidates_worksheet = interviewers_candidates_spreadsheet.worksheet(interviewers_selected_sheet_name)
        interviewers_candidates_values = interviewers_candidates_worksheet.get_all_values()
        interviewers_competentions_df = pd.DataFrame(interviewers_candidates_values[6:], columns=interviewers_candidates_values[5])

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏—Ö –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
        interviewers_list = [interviewers_competentions_df.columns[0]] + interviewers_df['–°–æ—Ç—Ä—É–¥–Ω–∏–∫'].tolist() #–°–æ—Ç—Ä—É–¥–Ω–∏–∫ + —Å–ø–∏—Å–æ–∫ –∏–∑ –∫–∞—Ä—Ç—ã –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
        interviewers_to_drop = [col for col in interviewers_competentions_df.columns if all(intererviewer not in col for intererviewer in interviewers_list)]
        interviewers_competentions_df.drop(columns=interviewers_to_drop, inplace=True)

        # –ß–∏—Å—Ç–∏–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º
        interviewers_competentions_df.columns = ['–ù–∞–≤—ã–∫'] + list(interviewers_competentions_df.columns[1:])
        unsupported_columns = [column for column in interviewers_competentions_df.columns if 'Unnamed' in column]
        interviewers_competentions_df.drop(columns=unsupported_columns, inplace=True)
        empty_competentions_ids = interviewers_competentions_df[interviewers_competentions_df['–ù–∞–≤—ã–∫'].str.strip().str.len() == 0].index
        interviewers_competentions_df.drop(index=empty_competentions_ids, inplace=True)
        interviewers_competentions_df.dropna(subset='–ù–∞–≤—ã–∫', inplace=True)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫ –∏–º–µ–Ω–∞–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –∏—Ö —É—Ä–æ–≤–µ–Ω—å
        interviewers_competentions_df.columns = [
            col if col == '–ù–∞–≤—ã–∫' else f"{col} ({interviewers_df[[intr.lower() in col.strip().lower() for intr in interviewers_df['–°–æ—Ç—Ä—É–¥–Ω–∏–∫']]].iloc[0]['–£—Ä–æ–≤–µ–Ω—å']})"
            for col in interviewers_competentions_df.columns
        ]

        if show_interviewers:
            st.subheader("–°–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤")
            st.dataframe(interviewers_competentions_df, height=350)

        if rank_button_column.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ", key=f"btn_{key_prefix}s_rank"):

            # –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Ä–∞–Ω–∂–∏—Ä
            interviewers_rating = get_rating(
                requirements=requirements,
                competentions=interviewers_competentions_df.to_markdown(index=False),
                ranking_prompt=INTERVIEWER_RANKING_PROMPT
            )

            # –í—ã–≤–æ–∂—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            interviewers_result_data = []
            for worker in interviewers_rating:
                interviewers_result_data.append({
                    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': worker.name,
                    '–†–µ–π—Ç–∏–Ω–≥': f'{worker.rating}%',
                    '–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏': ', '.join(worker.goods),
                    '–ß—Ç–æ –ø–æ–¥—Ç—è–Ω—É—Ç—å': ', '.join(worker.bads)
                })

            st.success("–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
            st.dataframe(pd.DataFrame(interviewers_result_data), width=1600)

    
