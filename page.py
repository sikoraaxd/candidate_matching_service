from io import BytesIO
from dotenv import load_dotenv

import os
import re
import requests
import pandas as pd
import streamlit as st
from streamlit import session_state as ss
from ranker import get_rating, CANDIDATE_RANKING_PROMPT, INTERVIEWER_RANKING_PROMPT

import gspread
from google.oauth2.service_account import Credentials
from gspread.exceptions import SpreadsheetNotFound, APIError


load_dotenv()

# Google Spreadsheets API Service account key
SERVICE_ACCOUNT_INFO = {
    "type": os.getenv('gs_type'),
    "project_id": os.getenv('gs_project_id'),
    "private_key_id": os.getenv('gs_private_key_id'),
    "private_key": os.getenv('gs_private_key'),
    "client_email": os.getenv('gs_client_email'),
    "client_id": os.getenv('gs_client_id'),
    "auth_uri": os.getenv('gs_auth_uri'),
    "token_uri": os.getenv('gs_token_uri'),
    "auth_provider_x509_cert_url": os.getenv('gs_auth_provider_x509_cert_url'),
    "client_x509_cert_url": os.getenv('gs_client_x509_cert_url'),
    "universe_domain": os.getenv('gs_universe_domain')
}

# Permitted zones
SCOPES = [
    "https://www.googleapis.com/auth/spreadsheets",
    "https://www.googleapis.com/auth/drive"
]

# Google Spreadsheets authorization 
creds = Credentials.from_service_account_info(SERVICE_ACCOUNT_INFO, scopes=SCOPES)
client = gspread.authorize(creds)

    
# ---------------------------
# UI
# ---------------------------
ss.setdefault('completion_bytes', b'')
st.set_page_config(page_title="–†–∞–Ω–∂–∏—Ä–æ–≤—â–∏–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤", layout="wide")

st.markdown(
    """
        <style>
            .stButton > button {
                float: right;
            }
        </style>
    """,
    unsafe_allow_html=True
)

st.title("üîé –ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –∏ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤")

# –û–±—â–µ–µ –ø–æ–ª–µ –≤–≤–æ–¥–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
requirements = st.text_area(
    "‚úçÔ∏è –í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏:", 
    height=400, 
    key=f"requirements"
)

# –í–∫–ª–∞–¥–∫–∏
tab_candidates, tab_interviewers = st.tabs(["–ü–æ–¥–±–æ—Ä –∫–∞–Ω–¥–∏–¥–∞—Ç–∞", "–ü–æ–¥–±–æ—Ä –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞"])


# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–±–æ—Ä–∞ –º–æ–¥—ã —Å —É—á–µ—Ç–æ–º None
def mode_with_none(row):
    counts = row.value_counts(dropna=False)
    return counts.idxmax()  # —Å–∞–º–æ–µ —á–∞—Å—Ç–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ, –≤–∫–ª—é—á–∞—è None/NaN


# –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ –ø–æ–¥–±–æ—Ä–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
with tab_candidates:
    title = "–ü–æ–∏—Å–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞"
    key_prefix="candidate"

    subheader_column, rank_button_column = st.columns([1, 1])
    subheader_column.subheader(title)

    # –û—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
    spreadsheet = client.open("–ö–∞—Ä—Ç–∞ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–π DP")

    selected_sheet_name = None
    show_candidates = False
    include_staffing = False
    include_laboratory = False

    if requirements:
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã
            worksheets = spreadsheet.worksheets()
            sheet_names = [ws.title for ws in worksheets]                
            selected_sheet_name = st.selectbox(
                "üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é:",
                sheet_names,
                key=f"{key_prefix}_direction"
            )

            show_candidates = st.checkbox(
                "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤",
                value=True,
                key=f"chk_{key_prefix}s"
            )

            with st.container():
                st.markdown("###### –í–∫–ª—é—á–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤:")
                include_staffing = st.checkbox("–°—Ç–∞—Ñ—Ñ–∏–Ω–≥", key=f"chk_{key_prefix}s_staffing")
                include_laboratory = st.checkbox("–õ–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é", key=f"chk_{key_prefix}s_laboratory")

        except SpreadsheetNotFound:
            st.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞!", icon="üö®")
        except APIError as e:
            st.error(f"–û—à–∏–±–∫–∞ API: {e}", icon="üö®")
    else:
        st.info("–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é", icon="üí°")
    
    # –ö–æ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    if requirements and selected_sheet_name:
        # –ü–æ–ª—É—á–∞–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ —ç–∫—Å–ø–æ—Ä—Ç XLSX
        export_url = f"https://docs.google.com/spreadsheets/d/{spreadsheet.id}/export?format=xlsx"

        # –î–µ–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å —Å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–µ–π
        session = requests.Session()
        session.headers.update({"Authorization": f"Bearer {creds.token}"})
        response = session.get(export_url)

        # –ß–∏—Ç–∞–µ–º —Å—Ä–∞–∑—É –≤ pandas
        competentions_df = pd.read_excel(BytesIO(response.content), sheet_name=selected_sheet_name, header=5)
        competentions_df.columns = ['–ù–∞–≤—ã–∫'] + list(competentions_df.columns[1:])
        unsupported_columns = [column for column in competentions_df.columns if 'Unnamed' in column]
        competentions_df.drop(columns=unsupported_columns, inplace=True)
        competentions_df.dropna(how='all', inplace=True)

        # –£–¥–∞–ª—è—é –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç–æ–≤ (–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—ã –Ω–µ –≤—ã—Å—Ç—É–ø–∞—é—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤)
        pattern = r"(cnslt)"    
        cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
        competentions_df.drop(columns=cols_to_drop, inplace=True)

        if not include_staffing:
            pattern = r"(staff)"
            
            cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
            competentions_df.drop(columns=cols_to_drop, inplace=True)

        if not include_laboratory:
            pattern = r"(laba)"
            
            cols_to_drop = [col for col in competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
            competentions_df.drop(columns=cols_to_drop, inplace=True)

        if show_candidates:
            st.subheader("–°–ø–∏—Å–æ–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
            st.dataframe(competentions_df, height=250)

        if rank_button_column.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ", key=f"btn_{key_prefix}s_rank"):
            # –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Ä–∞–Ω–∂–∏—Ä
            rating = get_rating(
                requirements=requirements,
                competentions=competentions_df.to_markdown(index=False),
                ranking_prompt=CANDIDATE_RANKING_PROMPT
            )

            # –í—ã–≤–æ–∂—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            result_data = []
            for worker in rating:
                result_data.append({
                    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': worker.name,
                    '–†–µ–π—Ç–∏–Ω–≥': f'{worker.rating}%',
                    '–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏': ', '.join(worker.goods),
                    '–ß—Ç–æ –ø–æ–¥—Ç—è–Ω—É—Ç—å': ', '.join(worker.bads)
                })

            st.success("–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
            st.dataframe(pd.DataFrame(result_data), width=1600)


# –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ –≤–∫–ª–∞–¥–∫–∏ –ø–æ–¥–±–æ—Ä–∞ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
with tab_interviewers:
    title = "–ü–æ–∏—Å–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞"
    key_prefix="interviewer"

    subheader_column, rank_button_column = st.columns([1, 1])
    subheader_column.subheader(title)

    # –û—Ç–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
    interviewers_spreadsheet = client.open("–ö–∞—Ä—Ç–∞ –∏–Ω—Ç—Ä–µ–≤—å—é–µ—Ä–æ–≤")

    interviewers_selected_sheet_name = None
    show_interviewers = False
    include_consultant = False

    if requirements:
        try:
            # –ü–æ–ª—É—á–∏—Ç—å –∏ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å –≤—Å–µ –ª–∏—Å—Ç—ã
            worksheets = interviewers_spreadsheet.worksheets()
            sheet_names = [ws.title for ws in worksheets]                
            interviewers_selected_sheet_name = st.selectbox(
                "üìÇ –í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é:",
                sheet_names,
                key = f"{key_prefix}_direction"
            )

            show_interviewers = st.checkbox(
                "–ü–æ–∫–∞–∑–∞—Ç—å —Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤",
                value=True,
                key = f"chk_{key_prefix}s"
            )

            with st.container():
                st.markdown("###### –í–∫–ª—é—á–∏—Ç—å –≤ —Å–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤:")
                include_consultant = st.checkbox("–ö–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç—ã", key=f"chk_{key_prefix}s_consultant")

        except SpreadsheetNotFound:
            st.error("–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞!", icon="üö®")
        except APIError as e:
            st.error(f"–û—à–∏–±–∫–∞ API: {e}", icon="üö®")
    else:
        st.info("–í–≤–µ–¥–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏—é", icon="üí°")
    
    # –ö–æ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ —É–∫–∞–∑–∞–Ω–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ - –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ
    if requirements and interviewers_selected_sheet_name:
        session = requests.Session()
        session.headers.update({"Authorization": f"Bearer {creds.token}"})

        # 1. –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–∏—Ä–∞–µ–º –∏–∑ —Ç–∞–±–ª–∏—Ü –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤
        interviewers_export_url = f"https://docs.google.com/spreadsheets/d/{interviewers_spreadsheet.id}/export?format=xlsx"
        session = requests.Session()
        session.headers.update({"Authorization": f"Bearer {creds.token}"})
        response = session.get(interviewers_export_url)

        interviewers_df = pd.read_excel(BytesIO(response.content), sheet_name=interviewers_selected_sheet_name)
        unsupported_columns = [column for column in interviewers_df.columns if 'Unnamed' in column]
        interviewers_df.drop(columns=unsupported_columns, inplace=True)
        interviewers_df.dropna(how='all', inplace=True)

        # 2. –ê —Ç–µ–ø–µ—Ä—å –≤—ã–±–∏—Ä–∞–µ–º —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤
        session = requests.Session()
        session.headers.update({"Authorization": f"Bearer {creds.token}"})
        response = session.get(export_url)

        interviewers_competentions_df = pd.read_excel(BytesIO(response.content), sheet_name=interviewers_selected_sheet_name, header=5)
        interviewers_competentions_df.columns = ['–ù–∞–≤—ã–∫'] + list(interviewers_competentions_df.columns[1:])
        unsupported_columns = [column for column in interviewers_competentions_df.columns if 'Unnamed' in column]
        interviewers_competentions_df.drop(columns=unsupported_columns, inplace=True)
        interviewers_competentions_df.dropna(how='all', inplace=True)

        # –£–¥–∞–ª—è—é —Å—Ç–∞—Ñ—Ñ–∏–Ω–≥ –∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—é (—Å—Ç–∞—Ñ—Ñ–∏–Ω–≥ –∏ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è –Ω–µ –≤—ã—Å—Ç—É–ø–∞—é—Ç –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤)
        pattern = r"(staff|laba)"
        cols_to_drop = [col for col in interviewers_competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
        interviewers_competentions_df.drop(columns=cols_to_drop, inplace=True)

        # 3. –¢–µ–ø–µ—Ä—å –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ —É–¥–∞–ª—è–µ–º —Ç–µ—Ö —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, —á—Ç–æ –µ—Å—Ç—å –≤–æ –≤—Ç–æ—Ä–æ–º
        # –°–ø–∏—Å–æ–∫ —Ñ–∞–º–∏–ª–∏–π –∏–∑ –ø–µ—Ä–≤–æ–≥–æ df
        names_to_remove = []
        for name in list(interviewers_competentions_df.columns[1:]):
            if name.startswith("cnslt - "):
                names_to_remove.append(name.replace("cnslt - ", ""))
            else:
                names_to_remove.append(name)

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å—Ç–æ–ª–±—Ü—ã –≤—Ç–æ—Ä–æ–≥–æ df
        interviewers_df = interviewers_df[~interviewers_df['–°–æ—Ç—Ä—É–¥–Ω–∏–∫'].isin(names_to_remove)]

        if not include_consultant:
            pattern = r"(cnslt)"    
            
            cols_to_drop = [col for col in interviewers_competentions_df.columns if re.search(pattern, col, flags=re.IGNORECASE)]
            interviewers_competentions_df.drop(columns=cols_to_drop, inplace=True)

        for interviewer in interviewers_df['–°–æ—Ç—Ä—É–¥–Ω–∏–∫']:
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–≥–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ —Å–ø—Ä–∞–≤–∞ —Å –º–∞–∂–æ—Ä–∏—Ç–∞—Ä–Ω–æ–π –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–µ–π
            interviewers_competentions_df[interviewer] = interviewers_competentions_df.apply(mode_with_none, axis=1)

        if show_interviewers:
            st.subheader("–°–ø–∏—Å–æ–∫ –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–æ–≤")
            st.dataframe(interviewers_competentions_df, height=350)

        if rank_button_column.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ", key=f"btn_{key_prefix}s_rank"):

            # –ó–∞–ø—Ä–∞—à–∏–≤–∞—é —Ä–∞–Ω–∂–∏—Ä
            interviewers_rating = get_rating(
                requirements=requirements,
                competentions=interviewers_competentions_df.to_markdown(index=False),
                ranking_prompt=INTERVIEWER_RANKING_PROMPT
            )

            # –í—ã–≤–æ–∂—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            interviewers_result_data = []
            for worker in interviewers_rating:
                interviewers_result_data.append({
                    '–°–æ—Ç—Ä—É–¥–Ω–∏–∫': worker.name,
                    '–†–µ–π—Ç–∏–Ω–≥': f'{worker.rating}%',
                    '–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∫–æ–º–ø–µ—Ç–µ–Ω—Ü–∏–∏': ', '.join(worker.goods),
                    '–ß—Ç–æ –ø–æ–¥—Ç—è–Ω—É—Ç—å': ', '.join(worker.bads)
                })

            st.success("–†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            st.subheader("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏—è")
            st.dataframe(pd.DataFrame(interviewers_result_data), width=1600)

    